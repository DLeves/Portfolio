---
title: "Budapesti lakásárak elemzése"
author: "Dittrich Levente"
date: "`r Sys.Date()`"
output: 
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Ebben a portfolió fejezetben azt vizsgálom meg, hogy az [AMD](https://finance.yahoo.com/quote/AMD?p=AMD&.tsrc=fin-srch), [NVIDIA](https://finance.yahoo.com/quote/NVDA?p=NVDA&.tsrc=fin-srch) és [Intel](https://finance.yahoo.com/quote/INTC?p=INTC&.tsrc=fin-srch) vállalatok részvényeinak árfolyamára fogok VECM vagy VAR modellt illeszteni, attól függően, hogy van-e közös hosszútávú pályájuk.

Mindhárom vállalat székhelye a kaliforniai Santa Claraban található, azonban nem csak az a közös bennük, hanem a tevékenységük is hasonló. Ezek a vállalatok mind mikro- és grafikus proceszorokkal foglalkoznak elsősorban. A napi gyakoriságú részvényadatokat a Yahoo Finance-ről töltöm le, viszont egy meghatározott intervallumban, így reprodukálhatóak lesznek eredményeim.

# Kezdeti beállítások

## Használt package-ek

```{r warning=FALSE, message=FALSE}
library(quantmod)
library(tidyverse)
library(knitr)
library(urca)
library(lmtest)
library(aTSA)
library(vars)
library(tsDyn)
```

Egy részvénynek egy napra több értékei is lehet, például az adott napi maximum, minimum, a nyitó vagy záró értéke. A továbbiakban az egyes részvények záró értékeivel fogok dolgozni.

## Adatok megszerzése

```{r}
intel = getSymbols("INTC", src = "yahoo", auto.assign = F, from = "2010-01-01", to = "2023-06-01")
amd = getSymbols("AMD", src = "yahoo", auto.assign = F, from = "2010-01-01", to = "2023-06-01")
nvidia = getSymbols("NVDA", src = "yahoo", auto.assign = F, from = "2010-01-01", to = "2023-06-01")
```

## Adatok átalakítása

Érdemes az adatokat nem xts formátumban egyenként, hanem dataframe-ként egyben tárolni, hogy később könnyebb legyen a munka.

```{r}
df = data.frame(
  time = index(intel),
  intc = as.numeric(intel$INTC.Close),
  amd = as.numeric(amd$AMD.Close),
  nvda = as.numeric(nvidia$NVDA.Close)
)
rm(intel, amd, nvidia)
kable(head(df))
```

Az adatokat tartalmazó dataframe változói a következők:

| Változó neve | Leírás                                    | Mértékegység |
|:-------------|:------------------------------------------|:-------------|
| time         | Idő(az adott nap)                         | Dátum        |
| intc         | Az adott napi Intel részvény záró értéke  | \$           |
| amd          | Az adott napi AMD részvény záró értéke    | \$           |
| nvda         | Az adott napi NVIDIA részvény záró értéke | \$           |

3375 megfigyelés van mindhárom változóból, ez mindenképpen elegendő lesz a modellépítéshez.

# Adatvizualizáció

```{r}
ggplot(df, aes(x = time))+
  geom_line(aes(y = intc, col = "Intel"))+
  geom_line(aes(y = amd, col = "AMD"))+
  geom_line(aes(y = nvda, col = "NVIDIA"))+
  scale_y_continuous(labels = scales::dollar_format())+
  scale_color_manual(values = c("#ED1C24", "#0071C5", "#76B900"))+
  theme_minimal()+
  theme(legend.title = element_blank())+
  labs(x = "Idő", y = "Részvény árfolyam")
```

Már a grafikonon is látszik, hogy valószínűleg nem stacionerek az idősorok.

# Kointegréció tesztelése

Ahhoz, hogy tudja, hogy VEC(Vector Error Correction) vagy VAR(Vector AutoRegression) modellt kell használjak, meg kell állapítanom, hogy van-e közös hosszútávú pályájuk az idősoroknak. Kointegráció esetén VEC modell a megfelelő, míg ha nincs közös távú hosszútávú pályája az idósoroknak, akkor VAR modellt kell alkalmazzak.

Erre egy *Johansen-tesztet* fogok végezni. A teszt érdekessége, hogy több nullhipotézist is felvet. Ez esetben a nullhipotézisek a következők, melyekben *r* a közös hosszútávú pályák száma:

-   H0: $r = 0$ \| H1: $r > 0$
-   H0: $r \le 1$ \| H1: $r > 1$
-   H0: $r \le 2$ \| H1: $r > 2$

Mivel összesen 3 db idősorom van, ezért maximum 2 db közös hosszútávú pálya lehetséges (a kódban ez a *K* paraméter).

```{r}
johansen_test = ca.jo(df[,-1], type = "eigen",  K = 2, ecdet = "const", spec = "longrun")
summary(johansen_test)
```

A teszt egy jobboldali próba, ez azt jelenti, hogy akkor tudjuk elfogadni a nullhipotéziseket, ha az adott próbafüggvény kisebb vagy egyenlő a kritikus értéknél. $H0: r = 0$ Minden szokványos szignifikanciaszinten elfogadható. $H0: r \le 1$ Minden szokványos szignifikanciaszinten elfogadható. $H0: r \le 2$ Minden szokványos szignifikanciaszinten elfogadható.

Ilyen esetben én a kettő közös hosszútávú pályát venném kiindulópontnak, amennyiben nem lesz szignifikáns ECT2, akkor megfontolom az egy hosszútávú pályára váltást.

# Optimális késleltetés megtalálása

Meg kellene határozzam az optimális késleltetést a VEC modellhez. Ez több lépésben fog megtörténni, először az idősorok stacionaritását kell tesztelnem. Amennyiben van egységgyök az idősorban, akkor stacionerré kell alakítanom őket majd mintha VAR modellhez keresném, meg kell határozzam az optimális késleltetést az információs kritériumokat felhasználva.

## Stacionaritás

Az erős stacionaritás azt jelenti, hogy az idősorok minden véges dimenziós eloszlása eltolásinvariás. Ez egy olyan erős követelmény, amit inkább a valószínűségszámításban használnak gyakran, azonban ökonometriában túl szigorú követelmény, ezért szokás gyenge stacionaritással dolgozni. Ez azt jelenti, hogy az idősor szórása és várható értéke időben állandó. A stacionaritás teszteléséhez egy Augmented Dickey-Fuller tesztet fogok végezni.

Az ADF teszt hipotézisei:

-   H0: Az idősor nem stacioner, $\phi = 0$
-   H1: Az idősor stacionárius, $\phi \neq 0$

A teszt nem csak egyféle módon végzi a tesztet, random-walkkal, valamint random walkkal és trenddel is megnézi a stacionaritást.

```{r}
adf.test(df$intc)
adf.test(df$amd)
adf.test(df$nvda)
```

Egyik idősor esetében sem lehet elutasítani a nullhipotézist, minden idősorom stacionárius.

```{r}
adf.test(diff(df$intc))
adf.test(diff(df$amd))
adf.test(diff(df$nvda))
```

A differenciált idősorok már stacionerek, nincsen egységgyök a modellben. Minden esetben a p-értékek 1% alatt vannak, a nullhipotéziseket el lehet vetni.

## Késleltetés meghatározása

A differenciált idősorokat a dataframe-be lementem és így nézem meg az optimális lag-okat.

```{r}
df$d_intc = c(NA, diff(df$intc))
df$d_amd = c(NA, diff(df$amd))
df$d_nvda = c(NA, diff(df$nvda))

VARselect(df[-1,5:7], lag.max = 30)
```

Mind az AIC, mind az FPE nagyon nagy lag-okat javasol. Ezeknél az információs kritériumoknál szigorúbb Hannan-Quinn információs kritérium a 11-es késleltetést preferálja, míg az annál is szigorúbb Bayes-Schwartz értéke az 1-es késleltetésnél a legkisebb. Ebben az esetben a Hannan-Quinn infromációs kritérium szerint fogok dönteni, 11-es késleletés lesz az alapmodellemben a kettő darab hosszútávú közös pálya mellett.

# Modellépítés

## Alapmodell

```{r}
alapmodell = VECM(df[,2:4], lag = 11, r = 2)
summary(alapmodell)
```

A közös hosszútávú pálya koefficiensei csak az AMD esetében szignifikánsak. Ezek jelentése a következő az AMD esetében:

-   ECT1: amennyiben az AMD elmozdul az első közös hosszútávú pályától, akkor a következő időszakban 0,51%-al a távolodik még.
-   ECT2: amennyiben az AMD elmozdul a második közös hosszútávú pályától, akkor az elmozdulás 0,63%-át hozza be a következő időszakban.

Érdemes kiemelni a kontextus miatt, hogy az Intel a x86 CPU-k piacának nagy részét az [Intel dominálja](https://www.statista.com/statistics/735904/worldwide-x86-intel-amd-market-share/), míg a diszkrét GPU-k piacának nagy részét az [NVIDIA uralja](https://www.pcworld.com/article/1526632/intel-is-already-tied-with-amd-for-desktop-gpu-sales.html). A laptopokat is beleértve szintén az [Intel a legnagyobb szereplő](https://www.statista.com/statistics/754557/worldwide-gpu-shipments-market-share-by-vendor/) a GPU piacon. Azért érdemes külön választani a diszkrét és integrált GPU-k piacát, mivel a 2010-es évek végétől kezdődő kriptovaluta bányászatra elsősorban dedikált, asztali videókártyákat használnak, ami egy időben okozott is hiányt, mivel a bányászok rengeteg GPU-t vásároltak fel a piacról.

Valószínűnek tartom, hogy a két hosszútávú közös pálya a CPU és GPU piacokat jelenti. Ha a szignifikanciaszinttől függetlenül nézzük a pályák koefficienseit, akkor látható, hogy az első pályától való eltérésnél az Intel közeledik, míg az AMD és az NVIDIA távolodik a következő időszakban. A második hosszútávú közös pályát nézve pont fordított a helyzet: az eltérés hatására az Intel távolodik, míg az AMD és az NVIDIA ledolgozza az eltérés egy részét. Feltevésem szerint az első hosszútávú pálya a processzorgyártók hosszútávú pályája, míg a második közös hosszútávú pálya a GPU gyártóké.

Visszatérve az alapmodellre, nagyon érdekes, hogy az előző időszaki Intel árfolyam mindegyik részvényre negatív hatással van. Végig a 11 késleltetésig nagyrészt vannak szignifikáns együtthatók, egyedül a négyes késleltetésnél nincsen egyik egyenletben sem szingifikáns koefficiens.

## Modellszűkítés

A modellszelekció miatt megnéztem több, más paraméterű modellt, ezek közül kettőt emelnék ki:

Az egyik modellben egy közös hosszútávú pálya van 11 késleltetéssel:

```{r}
szukitett_modell1 = VECM(df[,2:4], lag = 11, r = 1)
summary(szukitett_modell1)
```

A másik modellben pedig megmaradt a kettő közös hosszútávú pálya, azonban a késleltetést a Bayes-Schwartz IC által preferált 1-es késleltetésre cseréltem.

```{r}
szukitett_modell2 = VECM(df[,2:4], lag = 1, r = 2)
summary(szukitett_modell2)
```

A modellek információs kritériumai:

| Modell      | ECT | Lag | AIC               | BIC        |
|:------------|:----|:----|:------------------|:-----------|
| Alap        | 2   | 11  | 6161.923 \*       | 6835.188   |
| Szűkített 1 | 1   | 11  | 6167.099          | 6822.002   |
| Szűkített 2 | 2   | 1   | 6467.342          | 6589.813 \*|
|             |     |     | \* *Legkisebb IC* |            |

Az AIC szerint az alapmodell a jobb, míg a BIC szerint az egy késleltetésű, ami érthető is, mivel akkor drasztikusan csökken a bevont változók száma. Mivel egyértelműen nem tudom eldönteni, hogy szűkítsem-e a modellt, ezért amellett döntök, hogy meghagyom az alapmodellt végleges modellnek, mert egészen a 11 lagig vannak szignifikáns magyarázó változók.

# Granger okság

A VEC modelleknél a Granger okság vizsgálata bonyolultabb, mint a VAR modelleknél, ezért előtte különböző

# Impulzus-válaszfüggvények

```{r}
plot(irf(alapmodell, impulse = "intl", response = "amd", n.ahead = 11, ortho = T))
```


# Becslési variancia dekompozíció
```{r}
fevd(alapmodell, n.ahead = 11)
```

